{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Detecting Emotions in Text with GloVe Embeddings\n",
        "**Name**: Meagan Choo-Kang"
      ],
      "metadata": {
        "id": "w0QX_5s3hkIa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "P6qZ9uPDiSQe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.svm import LinearSVC\n",
        "import pandas as pd\n",
        "\n",
        "from keras import layers\n",
        "from keras.layers import LSTM, Activation, Dropout, Dense, Input, MaxPooling1D, Conv1D, Flatten\n",
        "from tqdm import tqdm\n",
        "from keras.models import Model\n",
        "import string\n",
        "import re\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, make_scorer, confusion_matrix, accuracy_score, precision_score, recall_score, precision_recall_curve"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RY-sIA6ql1vw",
        "outputId": "c02a893c-4365-46de-cabe-615af4b12752"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-19 13:46:19--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip          7%[>                   ]  65.74M  5.14MB/s    eta 1m 47s ^C\n",
            "[glove.6B.zip]\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of glove.6B.zip or\n",
            "        glove.6B.zip.zip, and cannot find glove.6B.zip.ZIP, period.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess Dataset"
      ],
      "metadata": {
        "id": "HZRnVxX4x2Oa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stop words copied from: https://github.com/ketanvaidya25/IMDb-Movie-Sentiment-Analysis/blob/main/IMDb_Movie_Sentiment_Analysis.ipynb\n",
        "stopwords = [ \"@\", \"im\", \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\",\n",
        "             \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\",\n",
        "             \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\",\n",
        "             \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\",\n",
        "             \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\",\n",
        "             \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\",\n",
        "             \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\",\n",
        "             \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\",\n",
        "             \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\",\n",
        "             \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\",\n",
        "             \"your\", \"yours\", \"yourself\", \"yourselves\" ]"
      ],
      "metadata": {
        "id": "Sp7whSoi02Yr"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def remove_stopwords(df, category):\n",
        "  df[\"removed_stopwords_\" + category] = df[category].apply(lambda x : ' '.join([word for word in x.split() if word not in (stopwords)]))\n",
        "  return df\n",
        "\n",
        "def remove_tags(string):\n",
        "    result = re.sub('<.*?>','',string)\n",
        "    return result"
      ],
      "metadata": {
        "id": "b9Usoeue15DC"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read dataset\n",
        "df = pd.read_csv('tweet_emotions.csv')\n",
        "\n",
        "# Filter sentiments to just 8\n",
        "emotions = [\"anger\", \"worry\", \"happiness\", \"love\", \"sadness\", \"surprise\"]\n",
        "df = df[df['sentiment'].isin(emotions)]\n",
        "\n",
        "# Get the labels for the targets so we can keep track of their values\n",
        "# when targets get one-hot-encoded\n",
        "target_labels = sorted(list(df[\"sentiment\"].unique()))\n",
        "\n",
        "#Initialize OneHotEncoder\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "categorical_columns = df['sentiment'].to_numpy().reshape(-1, 1)\n",
        "\n",
        "# Apply one-hot encoding to the categorical columns\n",
        "one_hot_encoded = encoder.fit_transform(categorical_columns)\n",
        "\n",
        "#Create a DataFrame with the one-hot encoded columns\n",
        "one_hot_df = pd.DataFrame(one_hot_encoded, columns=target_labels)\n",
        "\n",
        "# Concatenate the one-hot encoded dataframe with the original dataframe\n",
        "df_encoded = pd.concat([df.reset_index(drop=True), one_hot_df.reset_index(drop=True)], axis=1)\n",
        "\n",
        "# Clean up content by removing unnecessary words\n",
        "# For future, would also be nice to remove twitter username\n",
        "df_encoded['content'] = df_encoded['content'].str.lower()\n",
        "df_clean = remove_stopwords(df_encoded, \"content\")\n",
        "df_clean['clean_content']= df_clean['removed_stopwords_content'].apply(lambda cw : remove_tags(cw))\n",
        "df_clean['clean_content'] = df_clean['clean_content'].str.replace('[{}]'.format(string.punctuation), ' ')\n",
        "display(df_clean.head())\n",
        "\n",
        "# Define targets and features\n",
        "x = df_clean['clean_content']\n",
        "y = df_clean[emotions]\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.1, random_state = 45)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "67DZTMHXCzF8",
        "outputId": "0013d9aa-5bd4-41b6-9bce-79bb86c7aebd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     tweet_id sentiment                                            content  \\\n",
              "0  1956967666   sadness  layin n bed with a headache  ughhhh...waitin o...   \n",
              "1  1956967696   sadness                funeral ceremony...gloomy friday...   \n",
              "2  1956968477     worry  re-pinging @ghostridah14: why didn't you go to...   \n",
              "3  1956968487   sadness  i should be sleep, but im not! thinking about ...   \n",
              "4  1956968636     worry               hmmm. http://www.djhero.com/ is down   \n",
              "\n",
              "   anger  happiness  love  sadness  surprise  worry  \\\n",
              "0    0.0        0.0   0.0      1.0       0.0    0.0   \n",
              "1    0.0        0.0   0.0      1.0       0.0    0.0   \n",
              "2    0.0        0.0   0.0      0.0       0.0    1.0   \n",
              "3    0.0        0.0   0.0      1.0       0.0    0.0   \n",
              "4    0.0        0.0   0.0      0.0       0.0    1.0   \n",
              "\n",
              "                           removed_stopwords_content  \\\n",
              "0       layin n bed headache ughhhh...waitin call...   \n",
              "1                funeral ceremony...gloomy friday...   \n",
              "2  re-pinging @ghostridah14: didn't go prom? bc b...   \n",
              "3  sleep, not! thinking old friend want. married ...   \n",
              "4                       hmmm. http://www.djhero.com/   \n",
              "\n",
              "                                       clean_content  \n",
              "0       layin n bed headache ughhhh...waitin call...  \n",
              "1                funeral ceremony...gloomy friday...  \n",
              "2  re-pinging @ghostridah14: didn't go prom? bc b...  \n",
              "3  sleep, not! thinking old friend want. married ...  \n",
              "4                       hmmm. http://www.djhero.com/  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-beca77fa-3627-4ca7-aeaf-d0295dc03d88\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>content</th>\n",
              "      <th>anger</th>\n",
              "      <th>happiness</th>\n",
              "      <th>love</th>\n",
              "      <th>sadness</th>\n",
              "      <th>surprise</th>\n",
              "      <th>worry</th>\n",
              "      <th>removed_stopwords_content</th>\n",
              "      <th>clean_content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1956967666</td>\n",
              "      <td>sadness</td>\n",
              "      <td>layin n bed with a headache  ughhhh...waitin o...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>layin n bed headache ughhhh...waitin call...</td>\n",
              "      <td>layin n bed headache ughhhh...waitin call...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1956967696</td>\n",
              "      <td>sadness</td>\n",
              "      <td>funeral ceremony...gloomy friday...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>funeral ceremony...gloomy friday...</td>\n",
              "      <td>funeral ceremony...gloomy friday...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1956968477</td>\n",
              "      <td>worry</td>\n",
              "      <td>re-pinging @ghostridah14: why didn't you go to...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>re-pinging @ghostridah14: didn't go prom? bc b...</td>\n",
              "      <td>re-pinging @ghostridah14: didn't go prom? bc b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1956968487</td>\n",
              "      <td>sadness</td>\n",
              "      <td>i should be sleep, but im not! thinking about ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>sleep, not! thinking old friend want. married ...</td>\n",
              "      <td>sleep, not! thinking old friend want. married ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1956968636</td>\n",
              "      <td>worry</td>\n",
              "      <td>hmmm. http://www.djhero.com/ is down</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>hmmm. http://www.djhero.com/</td>\n",
              "      <td>hmmm. http://www.djhero.com/</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-beca77fa-3627-4ca7-aeaf-d0295dc03d88')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-beca77fa-3627-4ca7-aeaf-d0295dc03d88 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-beca77fa-3627-4ca7-aeaf-d0295dc03d88');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ae5e154a-a7cd-46c0-b2cc-bbe987500e30\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ae5e154a-a7cd-46c0-b2cc-bbe987500e30')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ae5e154a-a7cd-46c0-b2cc-bbe987500e30 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"tweet_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 471,\n        \"min\": 1956967666,\n        \"max\": 1956968636,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1956967696,\n          1956968636,\n          1956968477\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"worry\",\n          \"sadness\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"funeral ceremony...gloomy friday...\",\n          \"hmmm. http://www.djhero.com/ is down\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"anger\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"happiness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"love\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sadness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5477225575051662,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"surprise\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"worry\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5477225575051662,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"removed_stopwords_content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"funeral ceremony...gloomy friday...\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clean_content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"funeral ceremony...gloomy friday...\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Embedding Layer with GloVe"
      ],
      "metadata": {
        "id": "1DOPKET4NRCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set up GloVe\n",
        "path_to_glove_file = \"glove.6B.100d.txt\"\n",
        "\n",
        "with open(path_to_glove_file, 'r', encoding='UTF-8') as f:\n",
        "  words = set()\n",
        "  word_to_vec_map = {}\n",
        "  for line in f:\n",
        "    w_line = line.split()\n",
        "    curr_word = w_line[0]\n",
        "    word_to_vec_map[curr_word] = np.array(w_line[1:], dtype=np.float64)\n",
        "\n",
        "print(\"Found %s word vectors.\" % len(word_to_vec_map))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9z7IEBKNkad",
        "outputId": "2de58ff5-40d5-4684-e58f-b8be07791666"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create word-to-index dictionary using Tokenizer\n",
        "# key = word, value = index of word\n",
        "token = Tokenizer()\n",
        "\n",
        "# trains tokenizer\n",
        "token.fit_on_texts(x)\n",
        "\n",
        "# converts sentence to numeric form\n",
        "seq = token.texts_to_sequences(x)\n",
        "\n",
        "# add padding to make the lengths all the same\n",
        "maxLen = 1000\n",
        "pad_seq = pad_sequences(seq,maxlen=maxLen)\n",
        "\n",
        "# dictionary mapping words to their index\n",
        "words_to_index = token.word_index"
      ],
      "metadata": {
        "id": "8LBQwWvvNCtl"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EJwepaZuefgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert features/training data to their index form\n",
        "X_train_indices = token.texts_to_sequences(X_train)\n",
        "\n",
        "# add padding to ensure same length\n",
        "X_train_indices = pad_sequences(X_train_indices, maxlen=maxLen, padding='post')\n",
        "print(X_train_indices.shape)\n"
      ],
      "metadata": {
        "id": "ql88_R2ASQlq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e0650aa-3222-4cd8-c324-25a1b95fc6ee"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(22474, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create embedding layer values"
      ],
      "metadata": {
        "id": "QzWa6gEIdOJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define embedding matrix\n",
        "vocab_len = len(words_to_index)+1\n",
        "embed_vector_len = word_to_vec_map['moon'].shape[0]\n",
        "\n",
        "# words that are not in the GloVe dictionary = 0\n",
        "emb_matrix = np.zeros((vocab_len, embed_vector_len))\n",
        "\n",
        "# find words in GloVe for embedding matrix\n",
        "for word, index in words_to_index.items():\n",
        "  embedding_vector = word_to_vec_map.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    emb_matrix[index, :] = embedding_vector\n",
        "\n",
        "# define embedding layer\n",
        "# maps words to their embedding vectors from the embedding matrix\n",
        "embedding_layer = keras.layers.Embedding(input_dim=vocab_len, output_dim=embed_vector_len, input_length=maxLen, weights = [emb_matrix], trainable=False)\n"
      ],
      "metadata": {
        "id": "XWewGT-kN80E"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Model"
      ],
      "metadata": {
        "id": "JsoSlHzy273F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def createModel(input_shape):\n",
        "\n",
        "  X_indices = Input(input_shape)\n",
        "\n",
        "  # Embedding layer\n",
        "  embeddings = embedding_layer(X_indices)\n",
        "\n",
        "  # Convolutional layer\n",
        "  X = Conv1D(filters=32, kernel_size=3, padding='same', activation='relu')(embeddings)\n",
        "\n",
        "  # Max pooling layer\n",
        "  X = MaxPooling1D(pool_size=2)(X)\n",
        "\n",
        "  # Hidden layers\n",
        "  X = LSTM(128, return_sequences=True)(X)\n",
        "\n",
        "  X = Dropout(0.5)(X)\n",
        "\n",
        "  X = LSTM(128, return_sequences=True)(X)\n",
        "\n",
        "  X = Dropout(0.5)(X)\n",
        "\n",
        "  # Flatten to make the model shape compatible\n",
        "  X = Flatten()(X)\n",
        "\n",
        "  # Output layer\n",
        "  X = Dense(6, activation='softmax')(X)\n",
        "\n",
        "  model = Model(inputs=X_indices, outputs=X)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "nuNj0zYAGSSP"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build model\n",
        "model = createModel(maxLen)\n",
        "adam = keras.optimizers.Adam(learning_rate = 0.01)\n",
        "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=[keras.metrics.CategoricalAccuracy()])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tN1XusrcmrJn",
        "outputId": "241b619f-7278-42ee-ff42-007242c59469"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1000)]            0         \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 1000, 100)         3421600   \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 1000, 32)          9632      \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPoolin  (None, 500, 32)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 500, 128)          82432     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 500, 128)          0         \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 500, 128)          131584    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 500, 128)          0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 64000)             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 6)                 384006    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4029254 (15.37 MB)\n",
            "Trainable params: 607654 (2.32 MB)\n",
            "Non-trainable params: 3421600 (13.05 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model"
      ],
      "metadata": {
        "id": "0K_QLdv3crGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train_indices, Y_train, batch_size=120, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aq3visE0gwj9",
        "outputId": "8e6b8ce9-a264-485b-d7a7-0636daff4535"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "188/188 [==============================] - 715s 4s/step - loss: 2.3148 - categorical_accuracy: 0.3521\n",
            "Epoch 2/5\n",
            "188/188 [==============================] - 717s 4s/step - loss: 1.3636 - categorical_accuracy: 0.4352\n",
            "Epoch 3/5\n",
            "188/188 [==============================] - 717s 4s/step - loss: 1.3310 - categorical_accuracy: 0.4506\n",
            "Epoch 4/5\n",
            "188/188 [==============================] - 696s 4s/step - loss: 1.3109 - categorical_accuracy: 0.4653\n",
            "Epoch 5/5\n",
            "188/188 [==============================] - 688s 4s/step - loss: 1.2772 - categorical_accuracy: 0.4782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Predictions & Results"
      ],
      "metadata": {
        "id": "o6B0XFPrfL7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set up testing data\n",
        "X_test_indices = token.texts_to_sequences(X_test)\n",
        "X_test_indices = pad_sequences(X_test_indices, maxlen=maxLen, padding='post')\n",
        "\n",
        "# get predictions\n",
        "y_val_pred = model.predict(X_test_indices)\n",
        "\n",
        "# clean up predictions\n",
        "y_pred_clean = []\n",
        "for rowIndex in range(len(y_val_pred)):\n",
        "  # find maximum value in each row to determine predicted emotion and set it to one\n",
        "  # while rest of predictions are 0\n",
        "  newRow =  [0 for element in range(6)]\n",
        "  max_value = max(y_val_pred[rowIndex])\n",
        "  max_index = np.where(y_val_pred[rowIndex] == max_value)[0][0]\n",
        "  newRow[max_index] = 1\n",
        "  y_pred_clean.append(newRow)\n",
        "\n",
        "# get performance metrics\n",
        "f1, precision, recall = f1_score(Y_test, y_pred_clean, average=None), precision_score(Y_test, y_pred_clean, average=None), recall_score(Y_test, y_pred_clean, average=None)\n",
        "print(\"f1 score: \", f1)\n",
        "print(\"precision: \", precision)\n",
        "print(\"recall: \", recall)\n"
      ],
      "metadata": {
        "id": "7OofdRcY75Ki",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "197ea28b-2ea5-4810-9882-296e4221400a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 42s 514ms/step\n",
            "f1 score:  [0.         0.54291939 0.44665461 0.42809365 0.22661397 0.        ]\n",
            "precision:  [0.         0.42788462 0.42367067 0.59259259 0.35390947 0.        ]\n",
            "recall:  [0.         0.74255066 0.47227533 0.33507853 0.16666667 0.        ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results\n",
        "|Results|  anger  | worry      | happiness | love    |sadness | surprise |\n",
        "| ------|------| -----------| ----------| ------------| --------|---------|\n",
        "|f1 score:| 0.  | 0.54291939 |0.44665461 | 0.42809365 | 0.22661397 | 0. |\n",
        "precision:| 0.  | 0.42788462 |0.42367067 |0.59259259 | 0.35390947   | 0. |  \n",
        "recall:   |0.   | 0.74255066 |0.47227533 | 0.33507853 | 0.16666667 |0. |       "
      ],
      "metadata": {
        "id": "AtUkr0efkoZY"
      }
    }
  ]
}